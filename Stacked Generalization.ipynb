{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b43bdb",
   "metadata": {},
   "source": [
    "# Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd1c795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 3899.7596004009247 seconds\n",
      "Execution time: 35.250779151916504 seconds\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Record the starting time\n",
    "start_time = time.time()\n",
    "\n",
    "images = [cv2.imread(file) for file in glob.glob(\"/home/t326h379/AffectNet-8Labels/train_set/train_set/images/*.jpg\")]\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Print or use the elapsed time as needed\n",
    "print(f\"Execution time: {elapsed_time} seconds\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Record the starting time\n",
    "start_time = time.time()\n",
    "\n",
    "train_images = np.array(images)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Print or use the elapsed time as needed\n",
    "print(f\"Execution time: {elapsed_time} seconds\")\n",
    "\n",
    "globe_loaded_images = [file.split(\"/\")[-1] for file in glob.glob(\"/home/t326h379/AffectNet-8Labels/train_set/train_set/images/*.jpg\")]\n",
    "\n",
    "import glob\n",
    "import os\n",
    "os.chdir('/home/t326h379/AffectNet-8Labels/train_set/train_set/annotations/')\n",
    "training_exp_file_count =[]\n",
    "for name in glob.glob('*.npy'):\n",
    "    a = name.split(\"_\")\n",
    "    if a[1].startswith(\"exp\"):\n",
    "        training_exp_file_count.append(name)\n",
    "        \n",
    "annotation_files_number_training = set()\n",
    "for i in range(len(training_exp_file_count)):\n",
    "    train_exp = training_exp_file_count[i].split(\"_\")\n",
    "    annotation_files_number_training.add(train_exp[0])\n",
    "    \n",
    "import pickle\n",
    "with open('Kritika_AffectNet_Training.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "    \n",
    "y_train = []\n",
    "for i in range(len(globe_loaded_images)):\n",
    "    y_train.append(int(b[globe_loaded_images[i].split(\".\")[0]]))\n",
    "    \n",
    "y_train = np.array(y_train)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# One-hot encode the target labels\n",
    "num_classes = 8  # Replace with the actual number of classes\n",
    "y_train_one_hot = to_categorical(y_train, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff74ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, MaxPooling2D, Conv2D, Flatten, \\\n",
    "    BatchNormalization, Activation, GlobalAveragePooling2D, DepthwiseConv2D, \\\n",
    "    Dropout, ReLU, Concatenate, Input, add, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724cc809",
   "metadata": {},
   "source": [
    "# Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48db3873",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_images, y_train_one_hot, stratify= y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adbf597",
   "metadata": {},
   "source": [
    "# Convert the Whole Training image to 32-bit floating-point format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00f84b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_float32 = X_train.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9826fecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(258885, 224, 224, 3) (258885, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_float32.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ee299b",
   "metadata": {},
   "source": [
    "# Stacked Generlaization to increase the predicitive performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0387a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv1D, Dense, MaxPooling1D, Input, Flatten, LSTM, Dropout, Bidirectional, LeakyReLU, Reshape, Lambda\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# performance matrices\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, auc\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score,matthews_corrcoef\n",
    "from tensorflow.keras.callbacks import Callback,EarlyStopping\n",
    "import random\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, recall_score, matthews_corrcoef, roc_curve, auc\n",
    "from tensorflow.keras import backend as K\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, Reshape\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import copy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from Bio import SeqIO\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, Lambda, LSTM\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.backend import expand_dims\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D, MaxPooling2D,GlobalMaxPooling1D\n",
    "from Bio import SeqIO\n",
    "import random\n",
    "import functools\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, Reshape, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import copy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from tensorflow.keras import models,layers,optimizers,regularizers\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score,matthews_corrcoef\n",
    "from tensorflow.keras.callbacks import Callback,EarlyStopping\n",
    "import random\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, recall_score, matthews_corrcoef, roc_curve, auc\n",
    "from tensorflow.keras import backend as K\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, Reshape\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import copy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from Bio import SeqIO\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, Lambda, LSTM\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.backend import expand_dims\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D, MaxPooling2D,GlobalMaxPooling1D\n",
    "from Bio import SeqIO\n",
    "import random\n",
    "import functools\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, Reshape, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import copy\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38db08fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/t326h379/AffectNet-8Labels/train_set/train_set/annotations/')\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db65103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "saved_model_vit = tf.keras.models.load_model('saved_model_vit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ea4207a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "permute (Permute)            (None, 3, 224, 224)       0         \n",
      "_________________________________________________________________\n",
      "vit (Custom>TFViTMainLayer)  {'last_hidden_state': (No 86389248  \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice (T (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "Dense_First_Layer (Dense)    (None, 128)               98432     \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Classification_Layer (Dense) (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 86,488,712\n",
      "Trainable params: 86,488,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "saved_model_vit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0885b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "os.chdir('/home/t326h379/AffectNet-8Labels/val_set/annotations/')\n",
    "saved_model_vgg = tf.keras.models.load_model('VGG19_finetune.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b290a60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 32,874,056\n",
      "Trainable params: 12,849,672\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "saved_model_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb07698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def define_stacked_model(members):\n",
    "        # update all layers in all models to not be trainable\n",
    "    for i in range(len(members)):\n",
    "        model = members[i]\n",
    "        for layer in model.layers:\n",
    "            # make not trainable\n",
    "            layer.trainable = False\n",
    "            # rename to avoid 'unique layer name' issue\n",
    "            layer._name = 'ensemble_' + str(i+1) + '_' + layer._name\n",
    "    # define multi-headed input\n",
    "    ensemble_visible = [model.input for model in members]\n",
    "    # concatenate merge output from each model\n",
    "    ensemble_outputs = [model.output for model in members]\n",
    "    merge = concatenate(ensemble_outputs)\n",
    "    hidden = Dense(16, activation='relu')(merge)\n",
    "    output = Dense(8, activation='softmax')(hidden)\n",
    "    model = Model(inputs=ensemble_visible, outputs=output)\n",
    "    # plot graph of ensemble\n",
    "#     plot_model(model, show_shapes=True, to_file='model_graph.png')\n",
    "    # compile\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def fit_stacked_model(model, inputX, inputy):\n",
    "    # prepare input data\n",
    "    X = inputX\n",
    "    # encode output data\n",
    "    inputy_enc = inputy\n",
    "    # fit model\n",
    "    model.fit(X, inputy_enc, epochs=10, verbose=1) \n",
    "    model.save(\"Stacked_Generalization_ViT_and_VGG_with_10_Epoch.h5\")\n",
    "   \n",
    "def predict_stacked_model(model, inputX):\n",
    "    # prepare input data\n",
    "    X = inputX\n",
    "    # make prediction\n",
    "    return model.predict(X, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "319f37c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(258885, 224, 224, 3) (258885, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_float32.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88527f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 models\n"
     ]
    }
   ],
   "source": [
    "train_input_X = [X_train_float32,X_train_float32]\n",
    "\n",
    "\n",
    "n_members = 2\n",
    "members = [saved_model_vit,saved_model_vgg]\n",
    "print('Loaded %d models' % len(members))\n",
    "\n",
    "stacked_model = define_stacked_model(members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6f6cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e41251b",
   "metadata": {},
   "source": [
    "# Train the Stacked Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c820b40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8091/8091 [==============================] - 18366s 2s/step - loss: 0.2495 - accuracy: 0.9379\n",
      "Epoch 2/10\n",
      "8091/8091 [==============================] - 18873s 2s/step - loss: 0.2011 - accuracy: 0.9481\n",
      "Epoch 3/10\n",
      "8091/8091 [==============================] - 18816s 2s/step - loss: 0.1988 - accuracy: 0.9482\n",
      "Epoch 4/10\n",
      "4539/8091 [===============>..............] - ETA: 2:17:24 - loss: 0.1960 - accuracy: 0.9488"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8091/8091 [==============================] - 18782s 2s/step - loss: 0.1978 - accuracy: 0.9485\n",
      "Epoch 5/10\n",
      "8091/8091 [==============================] - 18740s 2s/step - loss: 0.1973 - accuracy: 0.9485\n",
      "Epoch 6/10\n",
      "8091/8091 [==============================] - 18754s 2s/step - loss: 0.1963 - accuracy: 0.9487\n",
      "Epoch 7/10\n",
      "8091/8091 [==============================] - 18718s 2s/step - loss: 0.1956 - accuracy: 0.9485\n",
      "Epoch 8/10\n",
      "8091/8091 [==============================] - 18804s 2s/step - loss: 0.1951 - accuracy: 0.9485\n",
      "Epoch 9/10\n",
      "1835/8091 [=====>........................] - ETA: 4:01:28 - loss: 0.1965 - accuracy: 0.9486"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8091/8091 [==============================] - 18694s 2s/step - loss: 0.1949 - accuracy: 0.9481\n",
      "Epoch 10/10\n",
      "8091/8091 [==============================] - 19815s 2s/step - loss: 0.1942 - accuracy: 0.9486\n"
     ]
    }
   ],
   "source": [
    "fit_stacked_model(stacked_model, train_input_X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3889ec31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "ensemble_2_ensemble_2_input_1 ( [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block1_co (None, 224, 224, 64) 1792        ensemble_2_ensemble_2_input_1[0][\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block1_co (None, 224, 224, 64) 36928       ensemble_2_ensemble_2_block1_conv\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block1_po (None, 112, 112, 64) 0           ensemble_2_ensemble_2_block1_conv\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block2_co (None, 112, 112, 128 73856       ensemble_2_ensemble_2_block1_pool\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block2_co (None, 112, 112, 128 147584      ensemble_2_ensemble_2_block2_conv\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block2_po (None, 56, 56, 128)  0           ensemble_2_ensemble_2_block2_conv\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block3_co (None, 56, 56, 256)  295168      ensemble_2_ensemble_2_block2_pool\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block3_co (None, 56, 56, 256)  590080      ensemble_2_ensemble_2_block3_conv\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block3_co (None, 56, 56, 256)  590080      ensemble_2_ensemble_2_block3_conv\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block3_co (None, 56, 56, 256)  590080      ensemble_2_ensemble_2_block3_conv\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block3_po (None, 28, 28, 256)  0           ensemble_2_ensemble_2_block3_conv\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block4_co (None, 28, 28, 512)  1180160     ensemble_2_ensemble_2_block3_pool\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block4_co (None, 28, 28, 512)  2359808     ensemble_2_ensemble_2_block4_conv\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block4_co (None, 28, 28, 512)  2359808     ensemble_2_ensemble_2_block4_conv\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block4_co (None, 28, 28, 512)  2359808     ensemble_2_ensemble_2_block4_conv\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block4_po (None, 14, 14, 512)  0           ensemble_2_ensemble_2_block4_conv\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block5_co (None, 14, 14, 512)  2359808     ensemble_2_ensemble_2_block4_pool\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block5_co (None, 14, 14, 512)  2359808     ensemble_2_ensemble_2_block5_conv\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_1_ensemble_1_input_1 ( [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block5_co (None, 14, 14, 512)  2359808     ensemble_2_ensemble_2_block5_conv\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_1_ensemble_1_permute ( (None, 3, 224, 224)  0           ensemble_1_ensemble_1_input_1[0][\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block5_co (None, 14, 14, 512)  2359808     ensemble_2_ensemble_2_block5_conv\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_1_ensemble_1_vit (Cust {'last_hidden_state' 86389248    ensemble_1_ensemble_1_permute[0][\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_block5_po (None, 7, 7, 512)    0           ensemble_2_ensemble_2_block5_conv\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_1_ensemble_1_tf_op_lay (None, 768)          0           ensemble_1_ensemble_1_vit[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_flatten ( (None, 25088)        0           ensemble_2_ensemble_2_block5_pool\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_1_ensemble_1_Dense_Fir (None, 128)          98432       ensemble_1_ensemble_1_tf_op_layer\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_dense (De (None, 512)          12845568    ensemble_2_ensemble_2_flatten[0][\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_1_ensemble_1_dropout_7 (None, 128)          0           ensemble_1_ensemble_1_Dense_First\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_dropout ( (None, 512)          0           ensemble_2_ensemble_2_dense[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_1_ensemble_1_Classific (None, 8)            1032        ensemble_1_ensemble_1_dropout_74[\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_ensemble_2_dense_1 ( (None, 8)            4104        ensemble_2_ensemble_2_dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16)           0           ensemble_1_ensemble_1_Classificat\n",
      "                                                                 ensemble_2_ensemble_2_dense_1[0][\n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           272         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 8)            136         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 119,363,176\n",
      "Trainable params: 408\n",
      "Non-trainable params: 119,362,768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "stacked_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee18fe8",
   "metadata": {},
   "source": [
    "# Results after 10 epochs of meta classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37a4bb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28766, 224, 224, 3) (28766,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_Independent_float32.shape, y_test_without_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f53b13e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stack = stacked_model.predict([X_test_Independent_float32,X_test_Independent_float32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e880e588",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stack_without_one_hot = np.argmax(y_pred_stack, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ca88b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 6, 4])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_stack_without_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf8ef40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da8f725a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[ 5307   827   490   263    49    31   442    79]\n",
      " [  852 12138    56   152    15    25    80   124]\n",
      " [  721    79  1429    56    59    15   183     4]\n",
      " [  330   207    44   689    99     1    31     8]\n",
      " [   60    33    73   142   268    11    51     0]\n",
      " [   55    45    47     7    13   127    85     1]\n",
      " [  638    75   153    42    49    62  1455    14]\n",
      " [  104   191     9     3     1     5    17    45]]\n",
      "Accuracy on test set:    0.745950079955503\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix : \\n\",confusion_matrix(y_test_without_one_hot, y_pred_stack_without_one_hot))\n",
    "print(\"Accuracy on test set:   \",accuracy_score(y_test_without_one_hot,y_pred_stack_without_one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f7e2f",
   "metadata": {},
   "source": [
    "# Load the below model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2883e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_model.save(\"Stacked_Generalization_Meta_Trained_For_10_Epoch_Final_Stacked_Generalization_ViT_and_VGG_.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064a6de7",
   "metadata": {},
   "source": [
    "# See the predicitive performace on the independent test dataset through Stacked Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b35b9ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_Independent_float32 = X_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e2ea993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7f4e1be8be50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ae13447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28766, 224, 224, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_Independent_float32.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ce9ad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_without_one_hot =  np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d356df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stack = stacked_model.predict([X_test_Independent_float32,X_test_Independent_float32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d8c66bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stack_without_one_hot = np.argmax(y_pred_stack, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8b045d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 6, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_stack_without_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c6442df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63e06729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[ 5378   823   420   242    54    28   469    74]\n",
      " [  888 12145    43   120    15    26    90   115]\n",
      " [  762    79  1377    52    62    14   197     3]\n",
      " [  351   219    37   639   121     1    34     7]\n",
      " [   68    36    67   127   281     7    52     0]\n",
      " [   59    43    47     6    14   120    90     1]\n",
      " [  635    73   140    33    53    60  1482    12]\n",
      " [  110   191     7     3     1     5    17    41]]\n",
      "Accuracy on test set:    0.7461238962664256\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix : \\n\",confusion_matrix(y_test_without_one_hot, y_pred_stack_without_one_hot))\n",
    "print(\"Accuracy on test set:   \",accuracy_score(y_test_without_one_hot,y_pred_stack_without_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e768f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_model.save(\"Final_Stacked_Generalization_ViT_and_VGG_Done_by_suabsh.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7163a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import ViTFeatureExtractor, TFViTModel\n",
    "\n",
    "# Define or import your custom layers here\n",
    "base_model = TFViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(\"Final_Stacked_Generalization_ViT_and_VGG_Done_by_suabsh.h5\", custom_objects={\"TFViTModel\": base_model.__class__})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52f8f223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "ensemble_2_input_1 (InputLayer) [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block1_conv1 (Conv2D (None, 224, 224, 64) 1792        ensemble_2_input_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block1_conv2 (Conv2D (None, 224, 224, 64) 36928       ensemble_2_block1_conv1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block1_pool (MaxPool (None, 112, 112, 64) 0           ensemble_2_block1_conv2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block2_conv1 (Conv2D (None, 112, 112, 128 73856       ensemble_2_block1_pool[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block2_conv2 (Conv2D (None, 112, 112, 128 147584      ensemble_2_block2_conv1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block2_pool (MaxPool (None, 56, 56, 128)  0           ensemble_2_block2_conv2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block3_conv1 (Conv2D (None, 56, 56, 256)  295168      ensemble_2_block2_pool[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block3_conv2 (Conv2D (None, 56, 56, 256)  590080      ensemble_2_block3_conv1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block3_conv3 (Conv2D (None, 56, 56, 256)  590080      ensemble_2_block3_conv2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block3_conv4 (Conv2D (None, 56, 56, 256)  590080      ensemble_2_block3_conv3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block3_pool (MaxPool (None, 28, 28, 256)  0           ensemble_2_block3_conv4[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block4_conv1 (Conv2D (None, 28, 28, 512)  1180160     ensemble_2_block3_pool[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block4_conv2 (Conv2D (None, 28, 28, 512)  2359808     ensemble_2_block4_conv1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block4_conv3 (Conv2D (None, 28, 28, 512)  2359808     ensemble_2_block4_conv2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block4_conv4 (Conv2D (None, 28, 28, 512)  2359808     ensemble_2_block4_conv3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block4_pool (MaxPool (None, 14, 14, 512)  0           ensemble_2_block4_conv4[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block5_conv1 (Conv2D (None, 14, 14, 512)  2359808     ensemble_2_block4_pool[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block5_conv2 (Conv2D (None, 14, 14, 512)  2359808     ensemble_2_block5_conv1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_1_input_1 (InputLayer) [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block5_conv3 (Conv2D (None, 14, 14, 512)  2359808     ensemble_2_block5_conv2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_1_permute (Permute)    (None, 3, 224, 224)  0           ensemble_1_input_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block5_conv4 (Conv2D (None, 14, 14, 512)  2359808     ensemble_2_block5_conv3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "vit (TFViTMainLayer)            TFBaseModelOutputWit 86389248    ensemble_1_permute[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_block5_pool (MaxPool (None, 7, 7, 512)    0           ensemble_2_block5_conv4[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_f_op_layer_strided_ (None, 768)          0           vit[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_flatten (Flatten)    (None, 25088)        0           ensemble_2_block5_pool[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_1_Dense_First_Layer (D (None, 128)          98432       tf_op_layer_f_op_layer_strided_sl\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_dense (Dense)        (None, 512)          12845568    ensemble_2_flatten[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_1_dropout_74 (Dropout) (None, 128)          0           ensemble_1_Dense_First_Layer[0][0\n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_dropout (Dropout)    (None, 512)          0           ensemble_2_dense[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_1_Classification_Layer (None, 8)            1032        ensemble_1_dropout_74[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ensemble_2_dense_1 (Dense)      (None, 8)            4104        ensemble_2_dropout[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16)           0           ensemble_1_Classification_Layer[0\n",
      "                                                                 ensemble_2_dense_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           272         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            136         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 119,363,176\n",
      "Trainable params: 86,389,656\n",
      "Non-trainable params: 32,973,520\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f380e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
